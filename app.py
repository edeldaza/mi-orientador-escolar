import streamlit as st
import google.generativeai as genai

# --- CONFIGURACI칍N DE LA P츼GINA ---
st.set_page_config(page_title="Orientador Escolar", page_icon="游꿉")

st.title("游꿉 Espacio de Escucha Escolar")
st.markdown("""
    Bienvenido. Soy un asistente virtual dise침ado para escucharte y orientarte.
    
    丘멆잺 **Importante:** Soy una IA, no un humano. Si est치s en peligro, busca a un profesor inmediatamente.
""")

# --- CONEXI칍N CON LA IA ---
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
    # CAMBIO IMPORTANTE: Usamos 'gemini-pro' que es m치s compatible
    model = genai.GenerativeModel('gemini-pro')
except Exception as e:
    st.error("丘멆잺 Error: No se encontr칩 la API Key. Config칰rala en 'Secrets'.")
    st.stop()

# --- INSTRUCCIONES DE PERSONALIDAD ---
instrucciones = """
Eres un orientador escolar amable y emp치tico para j칩venes de bajos recursos.
1. Escucha activamente y valida sus emociones.
2. Da consejos cortos y pr치cticos.
3. IMPORTANTE: Si detectas ideas suicidas, abuso o violencia grave, responde SOLO con:
   "游뚿 Esta situaci칩n es muy delicada y necesitas ayuda humana urgente. Por favor, habla ya mismo con tu profesor o llama a la l칤nea 123."
"""

# --- GESTI칍N DEL HISTORIAL ---
if "mensajes" not in st.session_state:
    st.session_state.mensajes = []

# --- MOSTRAR CHAT EN PANTALLA ---
for mensaje in st.session_state.mensajes:
    with st.chat_message(mensaje["role"]):
        st.markdown(mensaje["content"])

# --- CAPTURAR TEXTO DEL ALUMNO ---
if texto_alumno := st.chat_input("Escribe aqu칤 lo que sientes..."):
    
    # 1. Guardar y mostrar mensaje del alumno
    st.session_state.mensajes.append({"role": "user", "content": texto_alumno})
    with st.chat_message("user"):
        st.markdown(texto_alumno)

    # 2. Generar respuesta
    try:
        chat = model.start_chat(history=[])
        # Gemini Pro prefiere recibir el prompt as칤:
        prompt_completo = f"Instrucciones del sistema: {instrucciones}\n\nMensaje del alumno: {texto_alumno}"
        
        respuesta = chat.send_message(prompt_completo)
        
        # 3. Guardar y mostrar respuesta de la IA
        st.session_state.mensajes.append({"role": "assistant", "content": respuesta.text})
        with st.chat_message("assistant"):
            st.markdown(respuesta.text)
            
    except Exception as e:
        st.error(f"Ocurri칩 un error: {e}")
